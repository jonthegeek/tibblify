---
title: "Overall Idea"
author: "Maximilian Girlich"
date: "10/9/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Objects and Collections

In essence an _object_ is something that can be converted to a one row tibble.
In practice this means that the names must pass `vec_as_names(repair = "check_unique")`,
i.e.

* every element must be named (so the `names` attribute must not be `NULL` and
  no element may have the name `""` or `NA`)
* the names must be unique

Examples:

* a one row tibble
* `list(x = 1, y = list(list(x = 1), list(x = 2)))`


In essence a _collection_ is something that can be converted to a tibble.
In practice this means that `vec_chop(collection)` produces a list of similar objects.

Examples:

* a tibble
* `list(list(x = 1), list(x = 2))`


A tibble can have three types of columns

* vector columns (the typical case), e.g. `tibble(x = 1:3)`
* dataframe columns, e.g. the column `df_col` in `tibble(x = 1:3, df_col = tibble(a = 1:3, b = c("a", "b", "c")))`
* list columns resp. `list_of()` columns, e.g. `tibble(x = list(1:3, 4L, 5:6))`, `tibble(x = list(list(a = 1, b = "abc")))`


## Specification

There are two types of input to `tibblify()`: an object or a collection

An collection is specified with `spec_df()` and returns a tibble where

* the number of columns is the number of specified fields and
* the number of rows is the number of objects in the collection.

For a single object it often makes sense to return a list but in some cases it
makes more sense to return a one row tibble. They are specified with `tib_object()`
resp. `tib_row()`.


### Why Use `tib_object()`?

For a single object it usually makes more sense to return a list to avoid having
to subset. For example a typical API response might be something like

```{r}
api_output <- list(
  status = "success",
  requested_at = "2021-10-26 09:17:12",
  data = list(
    list(x = 1),
    list(x = 2)
  )
)
```

When converting to a tibble there are two options. To convert to a one row tibble

```{r}
api_output_df1 <- tibble::tibble(
  status = "success",
  requested_at = "2021-10-26 09:17:12",
  data = list(tibble::tibble(x = 1:2))
)

api_output_df1
```

it is necessary to wrap `data` in a list. To access `data` one has to use
`api_output_df1$data[[1]]` which is not very nice.

Not wrapping `data` in a list is not really an option either

```{r}
api_output_df2 <- tibble::tibble(
  status = "success",
  requested_at = "2021-10-26 09:17:12",
  data = tibble::tibble(x = 1:2)
)

api_output_df2
```

This only works if there is only one multi-row tibble like `data`. Further, the
scalar fields like `status` got recycled and cannot be used in comparisons that easily
anymore.


### Specifying Fields

The exact output type of fields depend on whether the fields are specified in
`spec_df()`/`spec_row()` or `spec_object()`.

Therefore, the functions `tib_*()` describe the output type of the field in a
single object, i.e.

* `tib_scalar(ptype)`: a length one vector with type `ptype`
  * output in `spec_object()`: a scalar
  * output in `spec_df()`: a vector column
* `tib_vector(ptype)`: a vector of arbitrary length with type `ptype`
  * output in `spec_object()`: a vector
  * output in `spec_df()`: a list of `ptype` column
* `tib_list()`: a vector of arbitrary length and type; you should barely ever need this
  * output in `spec_object()`: a list
  * output in `spec_df()`: a list column
* `tib_row(...)`: an object with the fields `...`
  * output in `spec_object()`: a named list
  * output in `spec_df()`: a tibble column
* `tib_df(...)`: a collection of objects with the fields `...`
  * output in `spec_object()`: a tibble
  * output in `spec_df()`: a list of tibble column


The fields of an object have the following properties

* `key`: the key
* `required`:
  * `TRUE`: error if the field doesn't exist
  * `FALSE`: use a default value if the field doesn't exist
* `default`: value to use if field doesn't exist
  * only if `required = FALSE`
  * defaults to `vec_init(ptype)`
* `empty`: value to use if field is empty
  * TODO is this useful?
  * defaults to `vec_init(ptype)`
* `transform`: a function to apply to the value
  * the function is applied first, then the casted value is assigned


The object has the following properties

* `unknown_fields_action`: action to take if there are unspecified fields
  * `"inform"`: inform about unknown fields and output their guessed specification
  * `"error"`
  * `"ignore"`
* `known_fields`: fields to consider known for `unknown_fields_action`
  * only if `unknown_fields != "ignore"`


Output attributes
* `exists`: Does the key always, never or only sometimes exist?
  * this is useful to track if a field probably doesn't exist anymore or the path has changed
  * `"always"`
  * `"never"`
  * `"sometimes"`
  * `"required"`


## Open Questions

* allow to extract nested path?
  * Can be quite useful in some situations and avoids the need to unpack a nested tibble
  * More complicated to implement
  * Need to think about whether and which elements to consider known
* allow to specify a default parser for unknown fields?
  * Can be useful if you know that many fields have the same type
  * Doesn't feel right because 1) the output tibble might vary in number and positions of columns and 2) it goes against the spirit of a full specification of the output
* How to handle partially named objects?
  * Produce an error?
  * Produce an error only if `unknown_fields_action = "error"`?
  * Extra argument to set behaviour?
* How to handle objects with duplicate names?
  * Produce an error?
  * Produce an error only if `unknown_fields_action = "error"`?
  * Extra argument to set behaviour?
* have special functions for common types, e.g. `tib_scalar_int()`, `tib_int_vec()`
* Are there other examples for objects or collections?



## Tibblify

There are two basic approaches to tibblify a collection:

1. Row based: tibblify each object separately and row bind them in the end

```{r}
purrr::map(
  vec_chop(collection),
  function(object) tibblify(object, spec)
) %>% 
  vec_rbind()
```

* easy to reason about
* easy to implement and check
* can be implemented in `C` using the experimental `vctrs` `C` API

2. Column based (current approach): Iterate over the fields of the spec. Extract all values belonging to a key and then parse them according to the spec.

Pseudocode:
```{r}
out <- purrr::map(keys, function(key) vec_init(ptypes[[key]]))

row_index <- 0L
for (row in vec_chop(collection)) {
  row_index <- row_index + 1L
  for (field_index in seq_along(row)) {
    key <- names2(row)[field_index]
    value <- vec_cast(row[[field_index]], ptypes[[key]])
    check_size(value)
    vec_assign(out[[key]], row_index) <- value
  }
  check_required_keys()
}
```

* better memory efficiency
* faster
* probably a bit more difficult to implement
* cannot use `vctrs` `C` API (`vec_assign()` is not yet exported)

The column based approach could be implemented in `C` if `out` isn't initialized with the correct types but as a list of lists and using

```{r}
purrr::map2(
  out, ptypes,
  function(col, ptype) vec_c(!!!col, .ptype = ptype)
) %>% 
  new_data_frame()
```

in the end to convert to a data frame.
